## Overview
Regression is the relationship between 2 things, particularly how an independent variable affects a dependent variable. The relationship between them can literally be a line that averages out all of the data points.

The upside of these algorithms is that they're simple. The downside of these algorithms is that they're simple. 

In the example below, we look at statistical data between salary and years of experience. We draw a line that represents the average of all of the datapoints and we can use that line to predict a new data point. From the line, we can predict that someone with 6 years experience will make roughly $80k a year.

![[Linear Regression.png]]

"Any equation, that is a function of the dependent variables and a set of weights is called a regression function." [^1]

If you think about the equations that you used in physics and chemistry, a large majority of them describe this kind of relationship between two things. When it comes to neural networks, these relationships are often described using linear equations.
Ex:
$$ y = x_1 w_1 + x_2 w_2 + x_3 w_3...$$

Where $w$ represents the weights. The weights are learned during training by studying the relationship between the dependent and independent variables.

![[Pasted image 20230524103932.png]]

## Determining Linear Regression
Videos
[Linear Regression Theory](https://www.youtube.com/watch?v=zPG4NjIkCjc)
[How to Implement Linear Regression from Scratch](https://www.youtube.com/watch?v=ltXSoduiVwY)
Articles
[Linear Regression Explained](https://towardsdatascience.com/regression-explained-in-simple-terms-dccbcad96f61)

[^1]: https://towardsdatascience.com/regression-explained-in-simple-terms-dccbcad96f61