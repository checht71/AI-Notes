Catastrophic forgetting is when a model sees too many examples and begins to forget the previous examples that it has learned as a result. This is especially the case in datasets with a very large number of classes such as CIFAR-100.

Ways to combat catastrophic forgetting is still an area of research in AI, but methods such as [[Replay]] seem to help somewhat.