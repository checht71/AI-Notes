Gradient Descent is the most commonly used [[Optimizers|optimizer]] function for neural networks.


## Stochastic Gradient Descent
You may have seen the term "stochastic gradient descent" used in different articles on machine learning, but what's the difference between this and regular gradient descent? In plain terms, "stochastic" means random.[^1]


[^1]: https://towardsdatascience.com/stochastic-gradient-descent-clearly-explained-53d239905d31


