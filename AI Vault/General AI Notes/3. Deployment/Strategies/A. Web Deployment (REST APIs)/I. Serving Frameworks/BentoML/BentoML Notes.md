https://www.youtube.com/watch?v=i_FtfdOKa2M



- ONLY the model is packaged into a bento, nothing else. If you want to preprocess your data, you have to do it using the service request.
- There are only a few datatypes which BentoML accepts

Should I bentoize and dockerize the model before putting it on azure or after? Can I download a service? I could host it off of lambda if I wanted but it would be expensive.